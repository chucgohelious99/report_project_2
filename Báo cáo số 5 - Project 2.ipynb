{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Báo cáo số 5\n",
    "\n",
    "* Họ và tên: Nguyễn Văn Chức\n",
    "* Mssv: 20170044\n",
    "* Nội dung tìm hiểu: Object Recogition trong Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection and Object Recognition\n",
    "\n",
    "Như đã trình bày trong báo cáo số 4, các thư viện trong Open CV cung cấp một số công cụ cho phép nhận diện và theo dõi vật thể dựa vào các đặc trưng. Tuy nhiên, các thuật toán dùng cho thư viện OpenCV này không thể đặt được hiệu suất làm việc cần thiết trong một số điều kiện nhất định."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Áp dụng Deep Learning trong Object Reconition\n",
    "\n",
    "Một số thuật toán Deep Learning cho phép nhận diện vật thể với hiệu suất cao hơn. Các thuật toán có thể kể đến như CNN(Convolutional Neural Network), R-CNN, Fast-RCNN, Faster-RCNN, RetinaNet và YOLO.\n",
    "\n",
    "### Thuật toán CNN\n",
    "\n",
    "Chúng ta có thể nhận thấy rằng với một phép tính Convolutional cho phép khảo sat một thuộc tính của bức ảnh. \n",
    "Một Neural NetWork bao gồm các layer được chia vào 3 loại:\n",
    "\\begin{itemize}\n",
    "\\item Convolution layer\n",
    "\\item Pooling layer\n",
    "\\item Fully connected layer\n",
    "\\end{itemize}\n",
    "\n",
    "Với Convolution Layer, một bức ảnh màu được khảo sát dưới dạng một bức ảnh RGB sẽ bao gồm 3 ma trận chứa thông tin ứng với 3 màu cơ bản do đó khi áp dụng thì kernel của phép tính Convolution sẽ là 1 tensor 3 chiều kích thước kxkx3.\n",
    "\n",
    "Trong một phép tính convolution, giá trị sau tính toán với kernel kxk tương ứng với từng màu chúng được cộng lại và thêm vào một số bias.\n",
    "\n",
    "Tuy nhiên, một kernel áp dụng chỉ cho phép cho ra 1 đầu ra. Chúng ta sẽ áp dụng K kernel để được đầu ra nhiều hơn. Đồng nghĩa với việc khảo sát nhiều thuộc tính qua một layer của mạng\n",
    "\n",
    "Các Pooling Layer được đặt xen kẽ giữa các Convolutional Layer nhằm giảm khối lương tính toán những vẫn đảm bảo giữ được đặc trưng cơ bản của bức ảnh. Một phép Pooling cũng có một kernel kích thước kxk và phép tính thay vì nhận các hệ số và công lại như trong convolution thì chọn giá trị max hoặc tính trung bình của các ô trong kernel. Đôi khi người ta sử dụng Convolutional Layer với hệ số stride > 1 để giảm kích thước tính toán thay cho việc sử dụng Pooling layer.\n",
    "\n",
    "Sau khi được Sau khi ảnh được truyền qua nhiều convolutional layer và pooling layer thì model đã học được tương đối các đặc điểm của ảnh thì tensor của output của layer cuối cùng,  sẽ được chuyển về dưới dạng vector 1 chiều. Sau đó ta dùng các fully connected layer để kết hợp các đặc điểm của ảnh để ra được output của model.\n",
    "\n",
    "\\begin{figure}[h]\n",
    "    \\centering\n",
    "    \\includegraphics[scale=1.0]{cnn.png}\n",
    "    \\caption{Mô hình cho phép nhận diện số viết tay}\n",
    "\\end{figure}\n",
    "\n",
    "Các thuật toán RCNN, Fast-RCNN, Faster-RCNN về cơ bản cũng là mô hình của CNN và kết hợp thêm các thuật toán khác để nâng cao hiệu quả thuật toán. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thuật toán YOLO\n",
    "\n",
    "Yolo là một mô hình mạng CNN cho việc phát hiện, nhận dạng, phân loại đối tượng. Yolo được tạo ra từ việc kết hợp giữa các convolutional layers và connected layers.Trong đóp các convolutional layers sẽ trích xuất ra các feature của ảnh, còn full-connected layers sẽ dự đoán ra xác suất đó và tọa độ của đối tượng.\n",
    "\n",
    "Hình ảnh đầu vào được chia thành S x S các ô.  Đối với mỗi object trong hình ảnh, mỗi ô cần xác định xác suất vật thể có nằm trong ô đó hay không. Nói theo cách đó là ô mà tâm của vật thể rơi vào hay không.\n",
    "\n",
    "Môi ô dự đoán B bounding bõ và C lớp xác suất. Mỗi bounding box dự đoán tâm của box tương đối trong ô chứa nó cũng như kích thước của nó đối với toàn bộ bức ảnh,  và một giá trị confident score tính bằng tích của xác suất vật thể xuất hiện trong ô và giá trị IOU(pred,truth). Với IOU được tính bằng diện tích phần giao trên diện tích phần hợp của predicted bounding box và ground truth bounding box.\n",
    "\n",
    "Mạng nơ ron áp dụng có cấu trúc giống như CNN với max pooling layer và 2 fully connected layer ở cuối."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thực hành\n",
    "Các thư viện ImageAI Cung cấp các công cụ thực thi YOLO và RetinaNet với model được tạo sẵn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "# import tensorflow as tf\n",
    "\n",
    "detector= ObjectDetection()\n",
    "# đặt chế độ làm việc với RetinaNet\n",
    "# có thể dùng chế độ làm việc với YOLO bằng cách dùng hàm\n",
    "#detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "#load đặt đường dẫn đến model\n",
    "detector.setModelPath(\"/content/drive/My Drive/Python code/Project 2 Practice/objectDetection/resnet50_coco_best_v2.0.1.h5\")\n",
    "#laod model\n",
    "detector.loadModel()\n",
    "#detect object\n",
    "detections= detector.detectCustomObjectsFromImage(input_image=\"/content/drive/My Drive/Python code/Project 2 Practice/objectDetection/animal.jpg\",\\\n",
    "                                                  output_image_path=\"/content/drive/My Drive/Python code/Project 2 Practice/objectDetection/newanimal.jpg\")\n",
    "#in ra kết quả\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bức ảnh trước khi biến đổi\n",
    "\n",
    "\\begin{figure}[h]\n",
    "    \\centering\n",
    "    \\includegraphics[scale=1]{animal.jpg}\n",
    "    \\caption{Bức ảnh đầu vào}\n",
    "\\end{figure}\n",
    "\n",
    "Bức ảnh kết quả:\n",
    "\\begin{figure}[h]\n",
    "    \\centering\n",
    "    \\includegraphics[scale=1]{newanimal.jpg}\n",
    "    \\caption{Bức ảnh đầu ra}\n",
    "\\end{figure}\n",
    "\n",
    "Bức ảnh mới nhận diện được 4 chú mèo, còn chú mèo thứ 5 thì vẫn chưa thể nhận diện được (chú mèo ở bên phải ngoài cùng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoặc chúng ta có thể sử dụng thư viện của OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load Yolo\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Loading image\n",
    "img = cv2.imread(\"room_ser.jpg\")\n",
    "img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "height, width, channels = img.shape\n",
    "\n",
    "# Detecting objects\n",
    "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "# Showing informations on the screen\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "            \n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
    "cv2.imshow(\"room_detect_result\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bức ảnh đầu vào:\n",
    "\n",
    "\\begin{figure}[h]\n",
    "    \\centering\n",
    "    \\includegraphics[scale=1]{room_ser.jpg}\n",
    "    \\caption{Bức ảnh đầu vào}\n",
    "\\end{figure}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
